{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematics Notebook\n",
    "From results of the phi fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import time \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', size=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load Configurations\n",
    "There are several files with different results for phi-distributions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 files in the database.\n"
     ]
    }
   ],
   "source": [
    "database_files = glob.glob('database/fit/*.csv')\n",
    "print('Found %d files in the database.' % len(database_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_database_files(file_list):\n",
    "    \n",
    "    dataframe_store = {}\n",
    "    for f in file_list:\n",
    "        dataframe_store[f] = pd.read_csv(f)\n",
    "        \n",
    "    return dataframe_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe_store = load_database_files(database_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, fit the nominal phi distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nominal = pd.read_csv('database/fit/phi-dist-sys.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systematic Uncertainties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def database_filename_parser(file_name):\n",
    "    file_name = file_name.split('variation_')[-1].strip('.csv')\n",
    "    \n",
    "    tokens = file_name.split('_')\n",
    "    n_tokens = len(tokens)\n",
    "\n",
    "    parameter_name = '_'.join(tokens[0:n_tokens-1])\n",
    "    index = int(tokens[-1])\n",
    "    \n",
    "    return index, parameter_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_parameter_variation_dict(path_to_db = 'database/fit/'):\n",
    "\n",
    "    parameters = {}\n",
    "\n",
    "    database_files = glob.glob(path_to_db + 'variation*.csv')\n",
    "    \n",
    "    for database_file in database_files:\n",
    "        index, parameter = database_filename_parser(database_file)\n",
    "        \n",
    "        if parameter in parameters.keys():\n",
    "            parameters[parameter][index] = pd.read_csv(database_file)\n",
    "        else:\n",
    "            parameters[parameter] = {}\n",
    "            parameters[parameter][index] = pd.read_csv(database_file)\n",
    "            \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_systematic_sources_list(file_name):\n",
    "    systematic_sources = pickle.load(open(file_name, 'rb'))\n",
    "    \n",
    "    reverse_dict = {}\n",
    "\n",
    "    for key, value in systematic_sources.iteritems():\n",
    "        reverse_dict[value] = key\n",
    "    \n",
    "    return reverse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_variation = build_parameter_variation_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dist_dcr3', [1, -1])\n",
      "('dist_dcr1', [1, -1])\n",
      "('dist_vz', [1, -1])\n",
      "('dist_ecw', [1, -1])\n",
      "('dist_ec_edep', [1, -1])\n",
      "('dist_ecsf', [1, -1])\n",
      "('p_mes', [0, -1])\n",
      "('alpha', [1, -1])\n",
      "('dist_ecu', [1, -1])\n",
      "('dist_cc', [0, -1])\n",
      "('dist_ecv', [1, -1])\n"
     ]
    }
   ],
   "source": [
    "for key, value in parameter_variation.iteritems():\n",
    "    print(key, value.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "systematic_sources = load_systematic_sources_list('systematic_sources.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_systematics(nominal_fit, parameter_variation, systematic_sources):\n",
    "\n",
    "    nominal_fit_sys = nominal_fit.copy(deep = True)\n",
    "    nominal_fit_sys['sys_total'] = np.zeros(len(nominal_fit_sys))\n",
    "\n",
    "    for key in parameter_variation.keys():\n",
    "\n",
    "        min_index = parameter_variation[key].keys()[0]    \n",
    "        max_index = parameter_variation[key].keys()[-1]\n",
    "\n",
    "    \n",
    "        merged_data = pd.merge(parameter_variation[key][min_index], \n",
    "                 parameter_variation[key][max_index],\n",
    "                 on = ['axis', 'axis_bin'])\n",
    "\n",
    "        merged_data[systematic_sources[key]] = np.abs(merged_data.par_0_y - merged_data.par_0_x)\n",
    "        # merged_data['shift_1'] = np.abs(merged_data.par_1_y - merged_data.par_1_x)\n",
    "        # merged_data['shift_2'] = np.abs(merged_data.par_2_y - merged_data.par_2_x)\n",
    "\n",
    "        merge_cols = ['axis', 'axis_bin', systematic_sources[key]]\n",
    "        nominal_fit_sys = pd.merge(nominal_fit_sys, merged_data[merge_cols], \n",
    "                                   on = ['axis', 'axis_bin'])\n",
    "    \n",
    "        nominal_fit_sys.sys_total += nominal_fit_sys[systematic_sources[key]]**2\n",
    "\n",
    "    nominal_fit_sys.sys_total = np.sqrt(nominal_fit_sys.sys_total)\n",
    "    \n",
    "    return nominal_fit_sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nominal_fit_sys = add_systematics(nominal, parameter_variation, systematic_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nominal_fit_sys.to_csv('results/fit/sys.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
