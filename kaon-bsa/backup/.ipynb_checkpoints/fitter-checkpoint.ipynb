{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Notebook\n",
    "Here we fit the phi-distributions from the analysis notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pymc3 as pm \n",
    "import sys\n",
    "import time \n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', size=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Fitting \n",
    "Our model is defined below, it can be one of several different functions.  Fitting is done by minimizing the $\\chi^2$.  Errors are estimated with the covariance matrix, or the bootstrap replica method.  Cross validation is defined, and the different models are evaluated.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chi2(y_true, y_pred, y_err):\n",
    "    return np.sum((y_true-y_pred)**2/y_err**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_pars = 1\n",
    "        self.pars   = np.zeros(shape=(self.n_pars, 1))\n",
    "        self.bounds = np.array([[-1, 1],], dtype=np.float32)\n",
    "        \n",
    "    def get_initial_parameters(self):\n",
    "        self.pars = np.random.uniform(-1.0, 1.0, size=(self.n_pars, 1))\n",
    "\n",
    "    def evaluate(self, x):\n",
    "        return 1.0\n",
    "\n",
    "class SineModel(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        Model.__init__(self)\n",
    "        self.n_pars = 1\n",
    "        self.pars = np.zeros(shape=(self.n_pars, 1), dtype=np.float32)\n",
    "        \n",
    "    def evaluate(self, x):\n",
    "        return self.pars[0]*np.sin( x*np.pi/180.0 )\n",
    "\n",
    "class FullModel(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        Model.__init__(self)\n",
    "        self.n_pars = 3\n",
    "        self.pars = np.zeros(shape=(self.n_pars, 1), dtype=np.float32)\n",
    "        self.bounds = np.array([[-1,1],\n",
    "                                [-1,1],\n",
    "                                [-1,1]],dtype=np.float32)\n",
    "    def evaluate(self, x):\n",
    "        return self.pars[0]*np.sin( x*np.pi/180.0 ) / (1 + self.pars[1]*np.cos(x*np.pi/180.0) + self.pars[2]*np.cos(2*x*np.pi/180.0))\n",
    "\n",
    "def update_model(model, pars, x):\n",
    "    model.pars = pars\n",
    "    return model.evaluate(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = FullModel()\n",
    "#model = SineModel()\n",
    "model.get_initial_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_fit(model, data, use_sys=False):\n",
    "    model.get_initial_parameters()\n",
    "    \n",
    "    if use_sys:\n",
    "        data_errs = np.sqrt(data.stat**2 + data.sys_total**2)\n",
    "    else:\n",
    "        data_errs = data.stat \n",
    "    \n",
    "    res = minimize(fun=lambda x: chi2(data.value, update_model(model, x, data.phi), data_errs), \n",
    "             x0=model.pars, bounds=model.bounds)\n",
    "\n",
    "    identity = np.identity(len(model.pars))\n",
    "    err = np.sqrt(np.array(np.matrix(res.hess_inv * identity).diagonal()))\n",
    "    #err.reshape(model.n_pars,1)\n",
    "    \n",
    "    return res.x, err[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_dataset(data, model, fit_type='single', use_sys=False):\n",
    "    '''\n",
    "    inputs\n",
    "    ------\n",
    "    \n",
    "    data: a dataframe which contains the output of the analysis notebook, phi-distributions \n",
    "    \n",
    "    model: a model object\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    result = {}\n",
    "    result['axis'] = []\n",
    "    result['axis_bin'] = []\n",
    "    result['axis_min'] = []\n",
    "    result['axis_max'] = []\n",
    "\n",
    "    \n",
    "    params = {}\n",
    "    params['axis'] = []\n",
    "    params['axis_bin'] = []\n",
    "    params['value'] = []\n",
    "    \n",
    "    for p in range(model.n_pars):\n",
    "        result['par_%d' % p] = []\n",
    "        result['err_%d' % p] = []\n",
    "        \n",
    "    for axis in np.unique(data.axis):\n",
    "        dsub = data.query('axis == \"%s\"' % axis)\n",
    "        \n",
    "        for bin in np.unique(dsub.axis_bin):\n",
    "            d = dsub.query('axis_bin == %d' % bin)\n",
    "            \n",
    "            \n",
    "            \n",
    "            if not use_sys:\n",
    "                data_errs = d.stat \n",
    "            else:\n",
    "                data_errs = np.sqrt(d.stat**2 + d.sys_total**2)\n",
    "                \n",
    "#            print(' Fitting %s,%d' % (axis, bin))\n",
    "            \n",
    "            # get fit to data\n",
    "            \n",
    "            if fit_type is 'single':\n",
    "                pars,errs = single_fit(model, d, use_sys)\n",
    "\n",
    "                params['value'].append(pars)\n",
    "            \n",
    "            elif fit_type is 'pymc3':\n",
    "                basic_model = pm.Model()\n",
    "\n",
    "                with basic_model:\n",
    "                    alpha = pm.Bound(pm.Normal, lower=-1, upper=1)('alpha', mu=0, sd=1)\n",
    "                    beta  = pm.Bound(pm.Normal, lower=-1, upper=1)( 'beta', mu=0, sd=0.05)\n",
    "                    gamma = pm.Bound(pm.Normal, lower=-1, upper=1)('gamma', mu=0, sd=0.05)\n",
    "    \n",
    "                    mu = alpha * np.sin( (np.pi/180) * d.phi) / (1 + \\\n",
    "                                                        beta * np.cos( (np.pi/180) * d.phi) + \\\n",
    "                                                        gamma * np.cos( 2*(np.pi/180) * d.phi)\n",
    "                                                        )\n",
    "        \n",
    "                    y = pm.Normal('y', mu=mu, sd=data_errs, observed=d.value)\n",
    "                    trace = pm.sample(1000, tune=500, progressbar=False)\n",
    "                    \n",
    "                    pars = []\n",
    "                    errs = []\n",
    "                    pars.append(np.average(trace['alpha']))\n",
    "                    pars.append(np.average(trace['beta']))\n",
    "                    pars.append(np.average(trace['gamma']))\n",
    "                    errs.append(np.std(trace['alpha']))\n",
    "                    errs.append(np.std(trace['beta']))\n",
    "                    errs.append(np.std(trace['gamma']))\n",
    "            \n",
    "                    params['value'].append(np.array([trace['alpha'],\n",
    "                                                    trace['beta'],\n",
    "                                                    trace['gamma']]))\n",
    "            \n",
    "            result['axis'].append(axis)\n",
    "            result['axis_bin'].append(bin)\n",
    "            result['axis_min'].append(d.axis_min.values[0])\n",
    "            result['axis_max'].append(d.axis_max.values[0])\n",
    "\n",
    "\n",
    "            params['axis'].append(axis)\n",
    "            params['axis_bin'].append(bin)\n",
    "            \n",
    "            for p in range(model.n_pars):\n",
    "                result['par_%d' % p].append(pars[p])\n",
    "                result['err_%d' % p].append(errs[p])\n",
    "            \n",
    "    return pd.DataFrame(result), params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Configurations\n",
    "There are several files with different results for phi-distributions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 files in the database.\n"
     ]
    }
   ],
   "source": [
    "database_files = glob.glob('../database/phi/*.csv')\n",
    "print('Found %d files in the database.' % len(database_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../database/phi/variation_dist_vz_1.csv',\n",
       " '../database/phi/variation_p_mes_-1.csv',\n",
       " '../database/phi/variation_p_mes_0.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_files = database_files[19:]\n",
    "database_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_database_files(file_list):\n",
    "    \n",
    "    dataframe_store = {}\n",
    "    for f in file_list:\n",
    "        dataframe_store[f] = pd.read_csv(f)\n",
    "        \n",
    "    return dataframe_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe_store = load_database_files(database_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_total_number_of_fits(dataframe_store):\n",
    "    total_fits = 0\n",
    "        \n",
    "    for file_name, dataframe in dataframe_store.iteritems():\n",
    "        axes = np.unique(dataframe.axis)\n",
    "        \n",
    "        for axis in axes:\n",
    "            total_fits += len(np.unique(dataframe.query('axis == \"%s\"' % axis).axis_bin))\n",
    "        \n",
    "    return total_fits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 fits will be performed.\n"
     ]
    }
   ],
   "source": [
    "total_fits = calculate_total_number_of_fits(dataframe_store)\n",
    "print('%d fits will be performed.' % total_fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_output_path(input_path):\n",
    "    return input_path.replace('phi', 'fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "/Users/dmriser/anaconda2/lib/python2.7/site-packages/pymc3/model.py:384: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if not np.issubdtype(var.dtype, float):\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8789981358068372, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8808929342222546, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8791702792980344, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8815236465243608, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8798350936172279, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File (1/3) finished in 435.373328 seconds."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8816484534137217, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8850400850053577, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8829372175216466, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8797233605252441, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8805461361201221, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File (2/3) finished in 908.712260 seconds."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8830986257745915, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8799986004715062, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8848506812791949, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8787395607702269, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8827405458934708, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8915753095988009, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8800613328181957, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8869759087500694, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8818537127042255, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8818142743318507, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8854437544188625, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.8802646197210829, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8801006075126421, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File (3/3) finished in 1439.895150 seconds."
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "t_start = time.time() \n",
    "for file_name in dataframe_store.keys():\n",
    "    \n",
    "    fit_df, pars = fit_dataset(dataframe_store[file_name], model, fit_type='pymc3', use_sys=False)\n",
    "    \n",
    "    output_path = get_output_path(file_name)\n",
    "    fit_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "    elapsed_time = time.time() - t_start \n",
    "    message_string = '\\rFile (%d/%d) finished in %f seconds.' % (index, len(dataframe_store.keys()), elapsed_time)\n",
    "    sys.stdout.write(message_string)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, fit the nominal phi distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nominal = pd.read_csv('results/phi-dist-sys.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8792911502084676, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8850516097081236, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.8846145204802365, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8853448654822311, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8829570637458621, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8866572597513038, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8810337884979071, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "The acceptance probability does not match the target. It is 0.8816543450225885, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.8829465610125439, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gamma_interval__, beta_interval__, alpha_interval__]\n"
     ]
    }
   ],
   "source": [
    "nominal_fit, nominal_pars = fit_dataset(nominal, \n",
    "                                        model, \n",
    "                                        fit_type='pymc3', \n",
    "                                        use_sys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systematic Uncertainties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def database_filename_parser(file_name):\n",
    "    file_name = file_name.split('variation_')[-1].strip('.csv')\n",
    "    \n",
    "    tokens = file_name.split('_')\n",
    "    n_tokens = len(tokens)\n",
    "\n",
    "    parameter_name = '_'.join(tokens[0:n_tokens-1])\n",
    "    index = int(tokens[-1])\n",
    "    \n",
    "    return index, parameter_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_parameter_variation_dict(path_to_db = 'database/fit/'):\n",
    "\n",
    "    parameters = {}\n",
    "\n",
    "    database_files = glob.glob(path_to_db + '*.csv')\n",
    "    \n",
    "    for database_file in database_files:\n",
    "        index, parameter = database_filename_parser(database_file)\n",
    "        \n",
    "        if parameter in parameters.keys():\n",
    "            parameters[parameter][index] = pd.read_csv(database_file)\n",
    "        else:\n",
    "            parameters[parameter] = {}\n",
    "            parameters[parameter][index] = pd.read_csv(database_file)\n",
    "            \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_systematic_sources_list(file_name):\n",
    "    systematic_sources = pickle.load(open(file_name, 'rb'))\n",
    "    \n",
    "    reverse_dict = {}\n",
    "\n",
    "    for key, value in systematic_sources.iteritems():\n",
    "        reverse_dict[value] = key\n",
    "    \n",
    "    return reverse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'database/fit/phi-dist-sy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f49d621465d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameter_variation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_parameter_variation_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-5ba8c67093b0>\u001b[0m in \u001b[0;36mbuild_parameter_variation_dict\u001b[0;34m(path_to_db)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdatabase_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatabase_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatabase_filename_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-eb3694a164d6>\u001b[0m in \u001b[0;36mdatabase_filename_parser\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mparameter_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_tokens\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'database/fit/phi-dist-sy'"
     ]
    }
   ],
   "source": [
    "parameter_variation = build_parameter_variation_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "systematic_sources = load_systematic_sources_list('systematic_sources.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_systematics(nominal_fit, parameter_variation, systematic_sources):\n",
    "\n",
    "    nominal_fit_sys = nominal_fit.copy(deep = True)\n",
    "    nominal_fit_sys['sys_total'] = np.zeros(len(nominal_fit_sys))\n",
    "\n",
    "    for key in parameter_variation.keys():\n",
    "\n",
    "        min_index = parameter_variation[key].keys()[0]    \n",
    "        max_index = parameter_variation[key].keys()[-1]\n",
    "\n",
    "    \n",
    "        merged_data = pd.merge(parameter_variation[key][min_index], \n",
    "                 parameter_variation[key][max_index],\n",
    "                 on = ['axis', 'axis_bin'])\n",
    "\n",
    "        merged_data[systematic_sources[key]] = np.abs(merged_data.par_0_y - merged_data.par_0_x)\n",
    "        # merged_data['shift_1'] = np.abs(merged_data.par_1_y - merged_data.par_1_x)\n",
    "        # merged_data['shift_2'] = np.abs(merged_data.par_2_y - merged_data.par_2_x)\n",
    "\n",
    "        merge_cols = ['axis', 'axis_bin', systematic_sources[key]]\n",
    "        nominal_fit_sys = pd.merge(nominal_fit_sys, merged_data[merge_cols], \n",
    "                                   on = ['axis', 'axis_bin'])\n",
    "    \n",
    "        nominal_fit_sys.sys_total += nominal_fit_sys[systematic_sources[key]]**2\n",
    "\n",
    "    nominal_fit_sys.sys_total = np.sqrt(nominal_fit_sys.sys_total)\n",
    "    \n",
    "    return nominal_fit_sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nominal_fit_sys = add_systematics(nominal_fit, parameter_variation, systematic_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nominal_fit_sys.to_csv('results/fit-sys.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
